# -*- coding: utf-8 -*-
"""Sentiment_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PMPT5rjxUbDGH6_Fym4RuZ2t0BiIiNT_

# **Sentiment analysis - Vader and Roberta model**

## Load Dataset
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('ggplot')

import nltk

df = pd.read_csv('/content/Reviews.csv')
df.head()

df = df.head(500)
print(df.shape)

df.head()

"""## Data preprocessing"""

dp = df['Score'].value_counts().sort_index()

ax = dp.plot(kind='bar',title = "Review count",figsize=(10,5),color = 'blue')
ax.set_xlabel("Star Rating")
ax.set_ylabel("Number of Reviews")
plt.show()

df.describe()

df.isnull().sum()

"""# **Vader model**"""

example = df['Text'][50]
print(example)

import nltk
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger_eng')
nltk.download('vader_lexicon')

tokens = nltk.word_tokenize(example)

tagged = nltk.pos_tag(tokens)
print(tagged)

from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm

sia = SentimentIntensityAnalyzer()

#example = This oatmeal is not good. Its mushy, soft, I don't like it. Quaker Oats is the way to go.
check = sia.polarity_scores(example)
print(check)

#polarity score on the entire dataset
res = {}
for i,row in tqdm(df.iterrows(),total = len(df)):
  text = row['Text']
  myid = row['Id']
  res[myid] = sia.polarity_scores(text)

vader = pd.DataFrame(res).T
vader = vader.reset_index().rename(columns = {'index':'Id'})
vader = vader.merge(df,how = 'left')

vader.head()

"""## **Results of VADER**"""

ax = sns.barplot(data=vader,x='Score',y='compound')
ax.set_title("Compound Score")
plt.show()

fig , ax = plt.subplots(1,3,figsize=(12,4))
sns.barplot(data=vader,x='Score',y='pos',ax=ax[0])
sns.barplot(data=vader,x='Score',y='neg',ax=ax[1])
sns.barplot(data=vader,x='Score',y='neu',ax=ax[2])
ax[0].set_title("Positive")
ax[1].set_title("Negative")
ax[2].set_title("Neutral")
plt.show()

"""# **Roberta Model**"""

from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment-latest"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

#Vader results on example
print(example)
sia.polarity_scores(example)

#Roberta results on example
def polarity_scores_roberta(example):
  encoded_text = tokenizer(example,return_tensors = 'pt')
  output = model(**encoded_text)
  scores = output[0][0].detach().numpy()
  scores = softmax(scores)
  scores_dict = {
    'roberta_neg' : scores[0],
    'roberta_neu' : scores[1],
    'roberta_pos' : scores[2]
  }
  return scores_dict

"""## **Results of  Roberta**"""

res = {}
for i,row in tqdm(df.iterrows(),total = len(df)):
  try:
    text = row['Text']
    myid = row['Id']
    vader_result = sia.polarity_scores(text)
    vader_result_rename = {}
    roberta_result = polarity_scores_roberta(text)
    both = {**vader_result, **roberta_result}
  res[myid] = both
  except RuntimeError:
    print(f'Broke for id {myid}')

result_df = pd.DataFrame(res).T
result_df = result_df.reset_index().rename(columns = {'index':'Id'})
result_df = result_df.merge(df,how = 'left')

"""# **Comaparing the results**"""

result_df.columns

"""# **Comparing the result**"""

sns.pairplot(data=result_df,vars=['neg', 'neu', 'pos',
                                  'roberta_neg', 'roberta_neu','roberta_pos']
             ,hue='Score',palette='tab10')
plt.show()

result_df.query('Score == 1').sort_values('roberta_pos',ascending=False)['Text'].values[0]

result_df.query('Score == 1').sort_values('roberta_neg',ascending=False)['Text'].values[0]

result_df.query('Score == 1').sort_values('pos',ascending=False)['Text'].values[0]

result_df.query('Score == 1').sort_values('neg',ascending=False)['Text'].values[0]

"""### Cleaning Notebook Metadata

Sometimes, Colab notebooks contain metadata (like widget states) that can cause issues when saving to platforms like GitHub. The following code will create a new, cleaner version of this notebook by removing such metadata. You can then download and upload this cleaned version to GitHub.
"""

import nbformat
import os

# Define the name of the current notebook
# !! IMPORTANT !!
# You need to replace 'Sentiment_analysis.ipynb' with the actual name of your notebook file.
# You can usually find this in the tab title of your browser or the URL.
# For example, if your notebook is titled "MyProject.ipynb", set:
notebook_name = 'Sentiment_analysis.ipynb' # <--- Update this to your notebook's actual name
cleaned_notebook_name = notebook_name.replace('.ipynb', '_cleaned.ipynb') if '.ipynb' in notebook_name else notebook_name + '_cleaned.ipynb'

# Get the current notebook path. Colab notebooks are typically in /content/
notebook_path = os.path.join('/content/', notebook_name)
cleaned_notebook_path = os.path.join('/content/', cleaned_notebook_name)

nb = None # Initialize nb to None

# Load notebook
try:
    with open(notebook_path, 'r', encoding='utf-8') as f:
        nb = nbformat.read(f, as_version=4)
except FileNotFoundError:
    print(f"Error: Notebook '{notebook_name}' not found. Please ensure the 'notebook_name' variable is correctly set to your current notebook's filename.")
    print("If you are unsure of the exact filename, you can check the browser tab title or the URL.")
except Exception as e:
    print(f"An unexpected error occurred while loading the notebook: {e}")


if nb is not None: # Only proceed if nb was successfully loaded
    # Remove widget metadata and execution counts
    if 'metadata' in nb and 'widgets' in nb.metadata:
        nb.metadata.pop('widgets', None)

    for cell in nb.cells:
        if 'metadata' in cell and 'execution_count' in cell.metadata:
            cell.metadata.pop('execution_count', None)
        # Optionally, clear outputs to reduce file size and potential metadata issues
        if 'outputs' in cell:
            cell['outputs'] = []

    # Save cleaned notebook
    with open(cleaned_notebook_path, 'w', encoding='utf-8') as f:
        nbformat.write(nb, f)

    print(f"Cleaned notebook saved as '{cleaned_notebook_name}'.")
    print("You can now download this file and upload it to GitHub, or use Colab's 'File > Upload notebook' feature to open it first and then save to GitHub.")
else:
    print("Notebook cleaning process aborted due to error during loading.")